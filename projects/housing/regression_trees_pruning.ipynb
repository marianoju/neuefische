{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baum-basierte Ansätze teilen den Eingabe-Raum $\\mathbb{R}^p$ rekursiv in $p$-dimensionale Quader $Q_m$ auf. Für jeden Quader wird im Fall des quadratischen Fehlers als Fehlermaß der Mittelwert $\\hat c_m$ verwendet. Beim Trainieren eines Regressionsbaums besteht die Schwierigkeit, ein geeignetes Abbruchkriterium zu finden. Mögliche Kriterien weitere Aufteilungen vorzunehmen sind: \n",
    "- die maximale Baumtiefe, \n",
    "- die Fehlerreduzierung einer Aufteilung, \n",
    "- die Anzahl an Trainingsbeispielen in einem Knoten. \n",
    "\n",
    "Die Wahl der maximalen Baumtiefe oder einen Schwellwert für die Fehlerreduzierung ist nicht einfach im Vorfeld festzulegen. Zudem kann es sein, dass ein Schwellwert für die Fehlerreduzierung bei einer Aufteilung nicht überschritten wird, jedoch eine darauffolgende Aufteilung zu einer größeren Reduzierung führen würde.\n",
    "\n",
    "Ein alternativer Ansatz zu diesen Abbruchkriterien ist das „*Pruning*“. Bei diesem Vorgehen werden die Abbruchkriterien sehr konservativ angesetzt und der Baum in Nachgang gestutzt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt verschiedene Ansätze das Pruning durchzuführen. Wir wollen uns hier das weakest-link-Pruning anschauen. Hierbei wird die Anpassung des Baumes an die Trainingsdaten mit der Komplexität des Baumes sanktioniert. \n",
    "\n",
    "Hierfür definiert man das Cost-Complexity-Kriterium $C_{\\alpha}$ für einen Baum $T$:\n",
    "\n",
    "$$C_{\\alpha}(T) = \\sum^{|T|}_{m=1}\\sum_{x_{i}\\in Q_m} (y_i-\\hat c_m)^2 + \\alpha |T| $$\n",
    "\n",
    "Die Idee ist nun für jedes $\\alpha$ einen Teilbaum $T_\\alpha \\subset T$ zu finden, der $C_{\\alpha}(T)$ minimiert. Das $\\alpha$ bestimmt man mittels eines Validierungsdatensatzes. \n",
    "\n",
    "Beim weakest-link-pruning sucht man sich den Knoten, der den kleinsten Anstieg pro Knoten von $\\sum^{|T|}_{m=1}\\sum_{x_{i}\\in Q_m} (y_i-\\hat c_m)^2$ zur Folge hat und fährt dann rekursiv fort, bis der Baum nur aus einem Knoten besteht. Man kann zeigen, dass diese Folge von Teilbäumen $T_\\alpha$ enthalten muss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:**\n",
    "- Implementiere das Pruning mit Hilfe von ```sklearn.tree._tree```\n",
    "- Teile die Daten in ```train```, ```validate```, ```test```. \n",
    "- Vergleiche den gestutzten Baum mit ungestutzten Bäumen verschiedener Tiefe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
